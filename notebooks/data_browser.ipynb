{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import struct\n",
    "import os.path\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "\n",
    "import cv2\n",
    "import hnswlib\n",
    "import networkx as nx\n",
    "# import plyvel\n",
    "\n",
    "from tensorflow.keras.applications import vgg16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory Graph Walker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryGraphWalker:\n",
    "    def __init__(self, memory_graph, knn = 30, accurate_prediction_limit = 10, distance_threshold = 0.1,  adjacency_radius = 2, identical_distance=0.01):\n",
    "\n",
    "        self.knn = knn\n",
    "        self.accurate_prediction_limit = accurate_prediction_limit\n",
    "        self.identical_distance = identical_distance\n",
    "        self.distance_threshold = distance_threshold\n",
    "        self.adjacency_radius = adjacency_radius\n",
    "\n",
    "        self.memory_graph = memory_graph\n",
    "        self.last_ids = dict()\n",
    "        self.predictions = dict()\n",
    "\n",
    "    \n",
    "    def add_parrelell_observations(self, file, t, pos, adj, feats):\n",
    "        return [self.add_observation(file, t, pos[i], adj[i], feats[i], i) for i in range(len(feats))]\n",
    "\n",
    "\n",
    "\n",
    "    def add_observation(self, file, t, pos, adj, feats, walker_id):\n",
    "\n",
    "        print(\"\\n-----------------------\\n\")\n",
    "        print(\"Walker\", walker_id, adj)\n",
    "        \n",
    "        observation_id = self.memory_graph.insert_observation({\"file\":file, \"t\":t, \"y\":pos[0], \"x\":pos[1]})\n",
    "\n",
    "        l = d = None\n",
    "\n",
    "        if self.memory_graph.index_count() >= self.knn:\n",
    "            labels, distances = self.memory_graph.knn_query([feats], k = self.knn)\n",
    "            l = labels[0]\n",
    "            d = distances[0]\n",
    "\n",
    "        if d is not None:\n",
    "            print(\"Nearest Neighbor\", d[0])\n",
    "\n",
    "        accurate_predictions = set()\n",
    "        evaluated_ids = set()\n",
    "\n",
    "        # find correct predictions and reinforce with adjacency\n",
    "        if adj and walker_id in self.predictions:\n",
    "            predictions = self.predictions[walker_id]\n",
    "\n",
    "            for pred in predictions:\n",
    "                a = pred[\"id_similar_to_prev\"]\n",
    "                b = pred[\"id_similar_to_curr\"]\n",
    "\n",
    "                if b in evaluated_ids:\n",
    "                    continue\n",
    "\n",
    "                f = pred['candidate_for_similar_to_curr'][\"f\"]\n",
    "\n",
    "                if self.memory_graph.distance(feats, f) <= self.distance_threshold:\n",
    "                    # print(\"add_predicted_observations\", b, observation_id)\n",
    "                    self.memory_graph.add_predicted_observations([b], [observation_id])\n",
    "                    accurate_predictions.add(a)\n",
    "                \n",
    "                if len(accurate_predictions) >= self.accurate_prediction_limit:\n",
    "                    print(\"Too many accurate_predictions\")\n",
    "                    break\n",
    "\n",
    "                evaluated_ids.add(b)\n",
    "\n",
    "            if len(predictions) > 0:\n",
    "                print(\"Predictions\", len(accurate_predictions), \"of\", len(predictions))\n",
    "        \n",
    "        print(\"frame\", t, pos)\n",
    "\n",
    "        if len(accurate_predictions) < self.accurate_prediction_limit:\n",
    "            \n",
    "            #if d is not None and sum([i < self.identical_distance for i in d]) > 3:\n",
    "            if d is not None and (d[0] < self.identical_distance):\n",
    "                node_id = l[0]\n",
    "                print(\"Using Identical\")\n",
    "            else:\n",
    "                node_id = self.memory_graph.insert_node({\"f\":feats})\n",
    "            \n",
    "            print(\"NodeID\", node_id)\n",
    "\n",
    "            self.memory_graph.add_integrated_observations([node_id], [observation_id])\n",
    "\n",
    "            if adj:\n",
    "                if walker_id in self.last_ids and self.last_ids[walker_id] is not None :\n",
    "                    self.memory_graph.insert_adjacency(self.last_ids[walker_id], node_id)\n",
    "\n",
    "                for a in accurate_predictions:\n",
    "                    self.memory_graph.insert_adjacency(a, node_id)\n",
    "        \n",
    "        else:\n",
    "            node_id = None\n",
    "\n",
    "        # make predictions\n",
    "        self.predictions[walker_id] = []\n",
    "\n",
    "        if self.memory_graph.index_count() >= self.knn and l is not None and d is not None:\n",
    "\n",
    "            similar = 0\n",
    "            \n",
    "            for n in range(self.knn):\n",
    "                label = l[n]\n",
    "                distance = d[n]\n",
    "                \n",
    "                if distance <= self.distance_threshold:\n",
    "                    # Found a previous similar observation\n",
    "\n",
    "                    # find other observations that have been seen near this one\n",
    "                    next_adjacencies = self.memory_graph.get_adjacencies(label, self.adjacency_radius)\n",
    "\n",
    "                    for n in next_adjacencies:\n",
    "                        props = self.memory_graph.get_node(n)\n",
    "                        self.predictions[walker_id].append(dict(id_similar_to_prev=label, id_similar_to_curr=n, candidate_for_similar_to_curr=props))\n",
    "\n",
    "                    similar += 1\n",
    "\n",
    "\n",
    "        self.last_ids[walker_id] = node_id\n",
    "\n",
    "        return node_id, observation_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryGraph:\n",
    "\n",
    "    def __init__(self, path, space='cosine', dim=512, max_elements=50000000, ef=100, M=48):\n",
    "        self.space = space\n",
    "        self.dim = dim\n",
    "        self.max_elements = max_elements\n",
    "        self.ef = ef\n",
    "        self.M = M\n",
    "        self.path = path\n",
    "        self.open()\n",
    "\n",
    "\n",
    "    def close(self):\n",
    "        self.db.close()\n",
    "        self.graph = None\n",
    "        self.index = None\n",
    "        self.db = None\n",
    "\n",
    "\n",
    "    def open(self):\n",
    "        self.db = plyvel.DB(self.path, create_if_missing=True)\n",
    "\n",
    "        self.graph = nx.Graph()\n",
    "\n",
    "        self.index = hnswlib.Index(space=self.space, dim=self.dim)     \n",
    "        self.index.init_index(max_elements=self.max_elements, ef_construction=self.ef, M=self.M)\n",
    "        self.index.set_ef(self.ef)\n",
    "\n",
    "        print(\"MemoryGraph: loading nodes\")\n",
    "        nodes = self.load_all_nodes()\n",
    "        for node in nodes:\n",
    "            self.graph.add_node(node[\"id\"], f=node[\"f\"])\n",
    "            self.index.add_items([node[\"f\"]], [node[\"id\"]])\n",
    "\n",
    "        print(\"MemoryGraph: loading edges\")\n",
    "        edges = self.load_all_edges()\n",
    "        for from_node_id, to_node_id in edges:\n",
    "            self.graph.add_edge(from_node_id, to_node_id)\n",
    "\n",
    "        print(\"MemoryGraph: loaded\", len(nodes), \"nodes,\", len(edges), \"edges\")\n",
    "\n",
    "\n",
    "    def increment_node_id(self, count):\n",
    "        return self.increment_id(count, b'd:n')\n",
    "\n",
    "    def increment_observation_id(self, count):\n",
    "        return self.increment_id(count, b'd:o')\n",
    "\n",
    "    def increment_id(self, count, key):\n",
    "        b = self.db.get(key)\n",
    "        if b is None:\n",
    "            node_id = count\n",
    "        else:\n",
    "            node_id = struct.unpack('>I', b)[0]\n",
    "            node_id += count\n",
    "        b = struct.pack('>I', node_id)\n",
    "        self.db.put(key, b)\n",
    "        return list(range(node_id-count+1, node_id+1))\n",
    "\n",
    "\n",
    "    ######################\n",
    "    # NODES\n",
    "    ######################\n",
    "\n",
    "    @staticmethod\n",
    "    def numpy_to_bytes(a):\n",
    "        return a.tobytes()\n",
    "\n",
    "    @staticmethod\n",
    "    def numpy_from_bytes(b):\n",
    "        return np.frombuffer(b, dtype=np.float32)\n",
    "\n",
    "    # node:[node_id] -> [node_data]\n",
    "    @staticmethod\n",
    "    def encode_node(node):\n",
    "        return MemoryGraph.numpy_to_bytes(node[\"f\"])\n",
    "\n",
    "    @staticmethod\n",
    "    def decode_node(k, v):\n",
    "        node = dict()\n",
    "        node[\"f\"] = MemoryGraph.numpy_from_bytes(v)\n",
    "        node[\"id\"] = struct.unpack_from('>I', k, offset=1)[0]\n",
    "        return node\n",
    "\n",
    "    @staticmethod\n",
    "    def node_key(node_id):\n",
    "        return b'n' + struct.pack('>I', node_id)\n",
    "\n",
    "    def get_node(self, node_id):\n",
    "        return self.graph.nodes[node_id]\n",
    "\n",
    "    def insert_node(self, node):\n",
    "        return self.insert_nodes([node])[0]\n",
    "\n",
    "    def load_all_nodes(self):\n",
    "        start = MemoryGraph.node_key(0)\n",
    "        stop = MemoryGraph.node_key(4294967295)\n",
    "        return [MemoryGraph.decode_node(key, value) for key, value in self.db.iterator(start=start, stop=stop)]\n",
    "\n",
    "    def get_nodes(self, node_ids):\n",
    "        return [self.get_node(node_id) for node_id in node_ids]\n",
    "\n",
    "    def insert_nodes(self, nodes):\n",
    "        node_ids = self.increment_node_id(len(nodes))\n",
    "        wb = self.db.write_batch()\n",
    "        for node_id, node in zip(node_ids, nodes):\n",
    "            self.graph.add_node(node_id, f=node[\"f\"])\n",
    "            self.index.add_items([node[\"f\"]], [node_id])\n",
    "            wb.put(MemoryGraph.node_key(node_id), MemoryGraph.encode_node(node))\n",
    "        wb.write()\n",
    "        return node_ids\n",
    "\n",
    "\n",
    "    ######################\n",
    "    # EDGES\n",
    "    ######################\n",
    "\n",
    "    @staticmethod\n",
    "    def edge_key(edge):\n",
    "        return b'e' + struct.pack('>I', edge[0]) + struct.pack('>I', edge[1])\n",
    "\n",
    "    def save_edges(self, edges):\n",
    "        wb = self.db.write_batch()\n",
    "        for from_node_id, to_node_id in edges:\n",
    "            wb.put(MemoryGraph.edge_key((from_node_id, to_node_id)), b'')\n",
    "        wb.write()\n",
    "\n",
    "    def load_all_edges(self):\n",
    "        start = MemoryGraph.edge_key((0,0))\n",
    "        stop = MemoryGraph.edge_key((4294967295, 4294967295))\n",
    "        return [(struct.unpack_from('>I', b, offset=1)[0], struct.unpack_from('>I', b, offset=5)[0]) for b in self.db.iterator(start=start, stop=stop, include_value=False)]\n",
    "\n",
    "\n",
    "    ######################\n",
    "    # OBSERVATIONS\n",
    "    ######################\n",
    "\n",
    "    # obs:[observation_id] -> [observation_data]\n",
    "    @staticmethod\n",
    "    def observation_key(observation_id):\n",
    "        return b'o' + struct.pack('>I', observation_id)\n",
    "\n",
    "    # get observation - observation is a dictionary\n",
    "    def get_observation(self, observation_id):\n",
    "        b = self.db.get(MemoryGraph.observation_key(observation_id))\n",
    "        return json.loads(b.decode(\"utf-8\") )\n",
    "\n",
    "    def insert_observation(self, observation):\n",
    "        return self.insert_observations([observation])[0]\n",
    "\n",
    "    def get_observations(self, observation_ids):\n",
    "        return [self.get_observation(observation_id) for observation_id in observation_ids]\n",
    "\n",
    "    def insert_observations(self, observations):\n",
    "        observation_ids = self.increment_observation_id(len(observations))\n",
    "        wb = self.db.write_batch()\n",
    "        for observation_id, observation in zip(observation_ids, observations):\n",
    "            j = json.dumps(observation)\n",
    "            b = j.encode(\"utf-8\")\n",
    "            wb.put(MemoryGraph.observation_key(observation_id), b)\n",
    "        wb.write()\n",
    "        return observation_ids\n",
    "\n",
    "    # integrated_observation:[node_id]:[observation_id]\n",
    "    @staticmethod\n",
    "    def integrated_observations_key(node_id, observation_id):\n",
    "        return b'i' + struct.pack('>I', node_id) + struct.pack('>I', observation_id)\n",
    "\n",
    "    # observations that are integrated into node's features\n",
    "    def get_integrated_observations(self, node_id):\n",
    "        start = MemoryGraph.integrated_observations_key(node_id, 0)\n",
    "        stop = MemoryGraph.integrated_observations_key(node_id, 4294967295)\n",
    "        return [struct.unpack_from('>I', b, offset=5)[0] for b in self.db.iterator(start=start, stop=stop, include_value=False)]\n",
    "\n",
    "    def add_integrated_observations(self, node_ids, observation_ids):\n",
    "        wb = self.db.write_batch()\n",
    "        for node_id, observation_id in zip(node_ids, observation_ids):\n",
    "            wb.put(MemoryGraph.integrated_observations_key(node_id, observation_id), b'')\n",
    "            wb.put(MemoryGraph.integrated_nodes_key(observation_id, node_id), b'')\n",
    "        wb.write()\n",
    "\n",
    "\n",
    "    # predicted_observation:[node_id]:[observation_id]\n",
    "    @staticmethod\n",
    "    def predicted_observations_key(node_id, observation_id):\n",
    "        return b'p' + struct.pack('>I', node_id) + struct.pack('>I', observation_id)\n",
    "\n",
    "    # observations that were predicted by node\n",
    "    def get_predicted_observations(self, node_id):\n",
    "        start = MemoryGraph.predicted_observations_key(node_id, 0)\n",
    "        stop = MemoryGraph.predicted_observations_key(node_id, 4294967295)\n",
    "        return [struct.unpack_from('>I', b, offset=5)[0] for b in self.db.iterator(start=start, stop=stop, include_value=False)]\n",
    "\n",
    "    def add_predicted_observations(self, node_ids, observation_ids):\n",
    "        wb = self.db.write_batch()\n",
    "        for node_id, observation_id in zip(node_ids, observation_ids):\n",
    "            wb.put(MemoryGraph.predicted_observations_key(node_id, observation_id), b'')\n",
    "            wb.put(MemoryGraph.predicted_nodes_key(observation_id, node_id), b'')\n",
    "        wb.write()\n",
    "\n",
    "\n",
    "    # predicted_node:[observation_id]:[node_id]\n",
    "    @staticmethod\n",
    "    def predicted_nodes_key(observation_id, node_id):\n",
    "        return b'q' + struct.pack('>I', observation_id) + struct.pack('>I', node_id)\n",
    "    \n",
    "    # nodes that predicted observation\n",
    "    def get_predicted_nodes(self, observation_id):\n",
    "        start = MemoryGraph.predicted_nodes_key(observation_id, 0)\n",
    "        stop = MemoryGraph.predicted_nodes_key(observation_id, 4294967295)\n",
    "        return [struct.unpack_from('>I', b, offset=5)[0] for b in self.db.iterator(start=start, stop=stop, include_value=False)]\n",
    "\n",
    "\n",
    "    # integrated_node:[observation_id]:[node_id]\n",
    "    @staticmethod\n",
    "    def integrated_nodes_key(observation_id, node_id):\n",
    "        return b'j' + struct.pack('>I', observation_id) + struct.pack('>I', node_id)\n",
    "\n",
    "    # nodes that integrate observation\n",
    "    def get_integrated_nodes(self, observation_id):\n",
    "        start = MemoryGraph.integrated_nodes_key(observation_id, 0)\n",
    "        stop = MemoryGraph.integrated_nodes_key(observation_id, 4294967295)\n",
    "        return [struct.unpack_from('>I', b, offset=5)[0] for b in self.db.iterator(start=start, stop=stop, include_value=False)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def get_adjacencies(self, node_id, radius):\n",
    "        return self._neighbors(node_id, radius)\n",
    "        \n",
    "\n",
    "    def _neighbors(self, v, radius, depth=0):\n",
    "        result = set()\n",
    "        for w in self.graph.neighbors(v):\n",
    "            result.add(w)\n",
    "            if depth + 1 < radius:\n",
    "                result.update(self._neighbors(w, radius, depth+1))\n",
    "        return result\n",
    "\n",
    "\n",
    "    def insert_adjacency(self, from_id, to_id):\n",
    "        self.save_edges([(from_id, to_id)])\n",
    "        self.graph.add_edge(from_id, to_id)\n",
    "\n",
    "\n",
    "    def knn_query(self, feats, k=1):\n",
    "        return self.index.knn_query(feats, k)   \n",
    "\n",
    "\n",
    "    def dnn_query(self, feature, distance):\n",
    "        k = 100\n",
    "        n = self.index.get_current_count()\n",
    "\n",
    "        while True:\n",
    "            if k > n:\n",
    "                k = n\n",
    "\n",
    "            _labels, _distances = self.index.knn_query([feature], k)  \n",
    "\n",
    "            labels = _labels[0]\n",
    "            distances = _distances[0]\n",
    "\n",
    "            if distances[-1] > distance:\n",
    "                idx = next(i for i,v in enumerate(distances) if v>distance)\n",
    "                if idx == 0:\n",
    "                    return [], []\n",
    "                return labels[:(idx-1)], distances[:(idx-1)]\n",
    "\n",
    "            if k == n:\n",
    "                return labels, distances\n",
    "\n",
    "            k = k * 2\n",
    "\n",
    "            print(\"dnn expand\", k)\n",
    "\n",
    "\n",
    "    def index_count(self):\n",
    "        return self.index.get_current_count()\n",
    "\n",
    "\n",
    "    def random_walk(self, start, l, trials):\n",
    "        visited = dict()\n",
    "\n",
    "        for _ in range(trials):\n",
    "            cur = start\n",
    "            for _ in range(l):\n",
    "                nei = list(self.graph.neighbors(cur))\n",
    "                if len(nei) == 0:\n",
    "                    break\n",
    "                cur = random.choice(nei)\n",
    "                if cur in visited:\n",
    "                    visited[cur] += 1\n",
    "                else:\n",
    "                    visited[cur] = 1\n",
    "    \n",
    "        nodes = []\n",
    "        count = []\n",
    "\n",
    "        if not bool(visited):\n",
    "            return [], []\n",
    "\n",
    "        for key, value in visited.items():\n",
    "            nodes.append(key)\n",
    "            count.append(value)\n",
    "\n",
    "        return zip(*sorted(zip(count, nodes), reverse=True))\n",
    "    \n",
    "\n",
    "    def get_community(self, node_id):\n",
    "        counts, node_ids = self.random_walk(node_id, 10, 1000)\n",
    "\n",
    "        n = 0\n",
    "        for i in range(len(counts)):\n",
    "            count = counts[i]\n",
    "            if count < 200:\n",
    "                break\n",
    "            n += 1\n",
    "\n",
    "        return node_ids[:n]\n",
    "\n",
    "\n",
    "    # the goal here is to search through the set of all communities and find all the ones that have a \n",
    "    # max_pool distance within a range of the max_pool distance of the query community\n",
    "    # candidate communities are ones that contain any member that is near any member of the quey community\n",
    "    def search_group(self, features, feature_dis, community_dis, k=30):\n",
    "        \n",
    "        results = set()\n",
    "        lab, dis = self.knn_query(features, k=k)\n",
    "        features_max = np.max(features, axis=0)\n",
    "        \n",
    "        visited_nodes = set()\n",
    "\n",
    "        for j in range(len(features)):\n",
    "            labels = lab[j]\n",
    "            distances = dis[j]\n",
    "\n",
    "            for i in range(k):\n",
    "                if distances[i] > feature_dis:\n",
    "                    # break because distance are sorted and only increase from here\n",
    "                    break\n",
    "                label = labels[i]\n",
    "\n",
    "                if label in visited_nodes:\n",
    "                    print(\"label in visited_nodes\")\n",
    "                    continue\n",
    "                visited_nodes.add(label)\n",
    "\n",
    "                community = self.get_community(label)\n",
    "                print(\"len(community)\", len(community))\n",
    "                if len(community) == 0:\n",
    "                    continue\n",
    "                community_features = np.array([self.get_node(c)[\"f\"] for c in community])\n",
    "                community_features_max = np.max(community_features, axis=0)\n",
    "                d = spatial.distance.cosine(community_features_max, features_max)\n",
    "                print(\"distance\", d)\n",
    "                if d <= community_dis:\n",
    "                    results.add(frozenset(community))\n",
    "\n",
    "        return results\n",
    "\n",
    "    def distance(self, a, b):\n",
    "        if self.space == 'cosine':\n",
    "            return spatial.distance.cosine(a, b)\n",
    "        else:\n",
    "            return np.linalg.norm(a-b)\n",
    "\n",
    "    def resize_frame(image):  \n",
    "        return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "colors = [\n",
    "    (1, 0, 103), (213, 255, 0), (255, 0, 86), (158, 0, 142), (14, 76, 161), (255, 229, 2), (0, 95, 57),\n",
    "    (0, 255, 0), (149, 0, 58), (255, 147, 126), (164, 36, 0), (0, 21, 68), (145, 208, 203), (98, 14, 0),\n",
    "    (107, 104, 130), (0, 0, 255), (0, 125, 181), (106, 130, 108), (0, 174, 126), (194, 140, 159), (190, 153, 112),\n",
    "    (0, 143, 156), (95, 173, 78), (255, 0, 0), (255, 0, 246), (255, 2, 157), (104, 61, 59), (255, 116, 163), \n",
    "    (150, 138, 232), (152, 255, 82), (167, 87, 64), (1, 255, 254), (255, 238, 232), (254, 137, 0), (189, 198, 255),\n",
    "    (1, 208, 255), (187, 136, 0), (117, 68, 177), (165, 255, 210), (255, 166, 254), (119, 77, 0), (122, 71, 130),\n",
    "    (38, 52, 0), (0, 71, 84), (67, 0, 44), (181, 0, 255), (255, 177, 103), (255, 219, 102), (144, 251, 146),\n",
    "    (126, 45, 210), (189, 211, 147), (229, 111, 254), (222, 255, 116), (0, 255, 120), (0, 155, 255), (0, 100, 1),\n",
    "    (0, 118, 255), (133, 169, 0), (0, 185, 23), (120, 130, 49), (0, 255, 198), (255, 110, 65), (232, 94, 190),\n",
    "    (0, 0, 0),\n",
    "]\n",
    "\n",
    "\n",
    "def get_rad_grid(g_pos, rad, shape):\n",
    "\n",
    "    top_left = (g_pos[0]-rad, g_pos[1]-rad)\n",
    "    g_width = math.floor((shape[0] - 32)/stride)\n",
    "    g_height = math.floor((shape[1] - 32)/stride)\n",
    "\n",
    "    res = []\n",
    "\n",
    "    for i in range(2*rad+1):\n",
    "        p = (top_left[0]+i, top_left[1])\n",
    "        if p[0] >= 0 and p[1] >= 0 and p[0] < g_width and p[1] < g_height:\n",
    "            res.append(p)\n",
    " \n",
    "    for i in range(2*rad+1):\n",
    "        p = (top_left[0]+i, top_left[1]+(2*rad+1))\n",
    "        if p[0] >= 0 and p[1] >= 0 and p[0] < g_width and p[1] < g_height:\n",
    "            res.append(p)\n",
    "\n",
    "    for i in range(2*rad-1):\n",
    "        p = (top_left[0], top_left[1]+(i+1))\n",
    "        if p[0] >= 0 and p[1] >= 0 and p[0] < g_width and p[1] < g_height:\n",
    "            res.append(p)\n",
    "\n",
    "    for i in range(2*rad-1):\n",
    "        p = (top_left[0]+(2*rad), top_left[1]+(i+1))\n",
    "        if p[0] >= 0 and p[1] >= 0 and p[0] < g_width and p[1] < g_height:\n",
    "            res.append(p)\n",
    "\n",
    "    #print(rad, g_pos, res)\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "def first_pos(kp_grid):\n",
    "    ## TODO: if there are no key points in frame\n",
    "    loc = random.choice(list(kp_grid.keys()))\n",
    "    return loc, random.choice(kp_grid[loc])\n",
    "\n",
    "\n",
    "\n",
    "def next_pos_play(kp_grid, shape, g_pos):\n",
    "    rad_grid = get_rad_grid(g_pos, 1, shape)\n",
    "    print(\"rad_grid\", rad_grid)\n",
    "    candidates = []\n",
    "\n",
    "    for loc in rad_grid:\n",
    "\n",
    "        if loc in kp_grid:\n",
    "            candidates.append(loc)\n",
    "\n",
    "\n",
    "    if len(candidates) == 0:\n",
    "        return None, None\n",
    "\n",
    "    loc = random.choice(candidates)\n",
    "\n",
    "    return loc, random.choice(kp_grid[loc])\n",
    "\n",
    "\n",
    "\n",
    "def next_pos(kp_grid, shape, g_pos):\n",
    " \n",
    "    if (g_pos is not None) and (random.random() > 1.0/walk_length):\n",
    "\n",
    "        for rad in range(1, 3):\n",
    "            rad_grid = get_rad_grid(g_pos, rad, shape)\n",
    "\n",
    "            if len(rad_grid) == 0:\n",
    "                print(\"frame empty?\")\n",
    "                break\n",
    "\n",
    "            random.shuffle(rad_grid)\n",
    "\n",
    "            for loc in rad_grid:\n",
    "                if loc in kp_grid:\n",
    "                    return loc, random.choice(kp_grid[loc]), True\n",
    "    \n",
    "    loc, pos = first_pos(kp_grid)\n",
    "    return loc, pos, False\n",
    "\n",
    "\n",
    "\n",
    "def extract_windows(frame, pos):\n",
    "    windows = np.empty((walker_count, window_size, window_size, 3))\n",
    "\n",
    "    for i in range(walker_count):\n",
    "        windows[i] = extract_window(frame, pos[i])\n",
    "\n",
    "    return windows\n",
    "\n",
    "\n",
    "\n",
    "def extract_window(frame, pos):\n",
    "    half_w = window_size/2.0\n",
    "    bottom_left = [int(round(pos[0]-half_w)), int(round(pos[1]-half_w))]\n",
    "    top_right = [bottom_left[0]+window_size, bottom_left[1]+window_size]\n",
    "   \n",
    "    if bottom_left[0] < 0:\n",
    "        top_right[0] -= bottom_left[0]\n",
    "        bottom_left[0] = 0\n",
    "\n",
    "    if bottom_left[1] < 0:\n",
    "        top_right[1] -= bottom_left[1]\n",
    "        bottom_left[1] = 0\n",
    "\n",
    "    if top_right[0] >= frame.shape[0]:\n",
    "        bottom_left[0] -= (top_right[0]-frame.shape[0]+1)\n",
    "        top_right[0] = frame.shape[0]-1\n",
    "\n",
    "    if top_right[1] >= frame.shape[1]:\n",
    "        bottom_left[1] -= (top_right[1]-frame.shape[1]+1)\n",
    "        top_right[1] = frame.shape[1]-1\n",
    "\n",
    "    return frame[bottom_left[0]:top_right[0], bottom_left[1]:top_right[1]]\n",
    "\n",
    "\n",
    "\n",
    "def key_point_grid(orb, frame):\n",
    "\n",
    "    kp = orb.detect(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY), None)\n",
    "\n",
    "    grid = dict()\n",
    "\n",
    "    grid_offset_x = ((frame.shape[0] - 32) % stride)/2.0 + 16\n",
    "    grid_offset_y = ((frame.shape[1] - 32) % stride)/2.0 + 16\n",
    "\n",
    "    for k in kp:\n",
    "        p = (k.pt[1],k.pt[0])\n",
    "        g = (int(math.floor((p[0]-grid_offset_x)/stride)), int(math.floor((p[1]-grid_offset_y)/stride)))\n",
    "        if g in grid:\n",
    "            grid[g].append(p)\n",
    "        else:\n",
    "            grid[g] = [p]\n",
    "\n",
    "    return grid\n",
    "\n",
    "\n",
    "\n",
    "def paint_windows(positions, windows, frame, rect=-1):\n",
    "    for i in range(len(positions)):\n",
    "        pos = positions[i]\n",
    "        x1 = int(round(pos[1] - window_size/2.0))\n",
    "        x2 = x1 + window_size\n",
    "        y1 = int(round(pos[0] - window_size/2.0))\n",
    "        y2 = y1 + window_size\n",
    "        \n",
    "        window = windows[i]\n",
    "\n",
    "        if abs(y1-y2) != window_size and abs(x1-x2) != window_size:\n",
    "            continue\n",
    "\n",
    "        wx1 = 0\n",
    "        wx2 = window_size\n",
    "        wy1 = 0\n",
    "        wy2 = window_size\n",
    "\n",
    "        shape = frame.shape\n",
    "\n",
    "        if y1 < 0:\n",
    "            if y1 < -window_size:\n",
    "                continue\n",
    "            wy1 = -y1\n",
    "            y1 = 0\n",
    "        if y2 >= shape[0]:\n",
    "            if y2 >= (shape[0] + window_size):\n",
    "                continue\n",
    "            wy2 = window_size - (y2 - shape[0] + 1)\n",
    "            y2 = shape[0]-1 \n",
    "        if x1 < 0:\n",
    "            if x1 < -window_size:\n",
    "                continue\n",
    "            wx1 = -x1\n",
    "            x1 = 0\n",
    "        if x2 >= shape[1]:\n",
    "            if x2 >= (shape[1] + window_size):\n",
    "                continue\n",
    "            wx2 = window_size - (x2 - shape[1] + 1)\n",
    "            x2 = shape[1]-1\n",
    "\n",
    "        frame[y1:y2, x1:x2] = window[wy1:wy2, wx1:wx2]\n",
    "\n",
    "        if rect > -1:\n",
    "            x1 = int(round(pos[1] - window_size/2.0))\n",
    "            x2 = int(round(pos[0] - window_size/2.0))\n",
    "            y1 = x1 + window_size\n",
    "            y2 = x2 + window_size\n",
    "\n",
    "            cv2.rectangle(frame, (y1, y2), (x1,x2), colors[rect % len(colors)], 1)\n",
    "\n",
    "\n",
    "def show_patches(path_windows, path_features, path_positions, frame_shape, memory_graph):\n",
    "    print(\"show_patches\")\n",
    "\n",
    "    cv2.namedWindow(\"patches\")\n",
    "\n",
    "    frame = np.zeros((frame_shape[0], frame_shape[1], 3), np.uint8)\n",
    "\n",
    "    paint_windows(path_positions, path_windows, frame, 0)\n",
    "\n",
    "    # features, feature_dis, community_dis, k=30\n",
    "    groups = list(memory_graph.search_group(path_features, .2, .2, 30))\n",
    "\n",
    "    print(\"groups\", groups)\n",
    "\n",
    "    for i in range(len(groups)):\n",
    "        group = list(groups[i])\n",
    "        \n",
    "\n",
    "        # node_ids = memory_graph.get_nodes(group)\n",
    "        \n",
    "        observation_ids = []\n",
    "        for node_id in group:\n",
    "            # print(\"node_id\", node_id)\n",
    "            integrated_observations = memory_graph.get_integrated_observations(node_id)\n",
    "            observation_ids.extend(integrated_observations)\n",
    "            predicted_observations = memory_graph.get_predicted_observations(node_id)\n",
    "            observation_ids.extend(predicted_observations)\n",
    "\n",
    "        windows = np.array([cv2.imread('./patches/patch'+str(observation_id)+'.png') for observation_id in observation_ids])\n",
    "\n",
    "        observations = memory_graph.get_observations(observation_ids)\n",
    "\n",
    "        positions = [(obs[\"y\"], obs[\"x\"]) for obs in observations]\n",
    "\n",
    "        paint_windows(positions, windows, frame, i+1)\n",
    "\n",
    "    cv2.imshow('patches', frame) \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph():\n",
    "\n",
    "    print(\"Starting...\")\n",
    "\n",
    "    orb = cv2.ORB_create(nfeatures=100000, fastThreshold=7)\n",
    "\n",
    "    # initialize VGG16\n",
    "    model = vgg16.VGG16(weights=\"imagenet\", include_top=False, input_shape=(32, 32, 3))\n",
    "\n",
    "    # memory graph\n",
    "    memory_graph = MemoryGraph(db_path, space='cosine', dim=512)\n",
    "    memory_graph_walker = MemoryGraphWalker(memory_graph, distance_threshold = 0.10, identical_distance=0.01)\n",
    "    \n",
    "    # for each run though the video\n",
    "    for r in range(runs):\n",
    "\n",
    "        print(\"Run\", r)\n",
    "\n",
    "        video_file_count = 0\n",
    "\n",
    "        for video_file in video_files:\n",
    "\n",
    "            video_file_count += 1\n",
    "\n",
    "            # open video file for a run though\n",
    "            cap = cv2.VideoCapture(video_dir + video_file)\n",
    "\n",
    "            if save_windows:\n",
    "                Path('./patches/' + video_file).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            # walkers\n",
    "            g_pos = [None for _ in range(walker_count)]\n",
    "            pos = [None for _ in range(walker_count)]\n",
    "            adj = [False for _ in range(walker_count)]\n",
    "\n",
    "            done = False\n",
    "\n",
    "            # for each frame\n",
    "            for t in range(max_frames):\n",
    "                if done:\n",
    "                    break\n",
    "\n",
    "                print(\"file\", video_file_count, video_file)\n",
    "\n",
    "                ret, frame = cap.read()\n",
    "                    \n",
    "                if ret == False:\n",
    "                    done = True\n",
    "                    break\n",
    "\n",
    "                frame = resize_frame(frame)\n",
    "\n",
    "                kp_grid = key_point_grid(orb, frame)\n",
    "\n",
    "                for i in range(walker_count):\n",
    "                    g_pos[i], pos[i], adj[i] = next_pos(kp_grid, frame.shape, g_pos[i])\n",
    "\n",
    "                windows = extract_windows(frame, pos)\n",
    "\n",
    "                # extract cnn features from windows\n",
    "                preprocess_input(windows)\n",
    "                feats = model.predict(windows)\n",
    "                feats = feats.reshape((windows.shape[0], 512))\n",
    "        \n",
    "                ids = memory_graph_walker.add_parrelell_observations(video_file, t, pos, adj, feats)\n",
    "\n",
    "                for i in range(walker_count):\n",
    "                    if ids[i][0] is None:\n",
    "                        # restart walk because we are in a very predictable spot\n",
    "                        g_pos[i] = None\n",
    "                        pos[i] = None\n",
    "                        adj[i] = False  \n",
    "                    if save_windows:\n",
    "                        cv2.imwrite('./patches/' + video_file + '/patch_' + str(ids[i][1]) + '.png', windows[i])\n",
    "\n",
    "            cap.release()\n",
    "\n",
    "    memory_graph.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class VideoPatchBrowser:\n",
    "    def __init__(self, video_file, ax1, ax2):\n",
    "        with out:\n",
    "            print(\"VideoPatchBrowser\")\n",
    "        # self.orb = cv2.ORB_create(nfeatures=100000, fastThreshold=7)\n",
    "        # self.memory_graph = MemoryGraph(db_path, space='cosine', dim=512)\n",
    "        # self.model = vgg16.VGG16(weights=\"imagenet\", include_top=False, input_shape=(32, 32, 3))\n",
    "        self.cap = cv2.VideoCapture(video_file) \n",
    "        self.ax1 = ax1\n",
    "        self.ax2 = ax2\n",
    "        self.next_frame()\n",
    "\n",
    "    def next_frame(self):\n",
    "        if self.cap.isOpened():  \n",
    "            ret, frame = self.cap.read() \n",
    "\n",
    "            if ret == True: \n",
    "                self.frame = frame\n",
    "                self.update_ax1()\n",
    "                return\n",
    "\n",
    "        with out:\n",
    "            print(\"No More Frames\")\n",
    "\n",
    "    def on_press(self, event):\n",
    "        with out:\n",
    "            print(\"on_press\")\n",
    "        self.next_frame()\n",
    "\n",
    "    def on_click(self, event):\n",
    "\n",
    "                \n",
    "        if ax1 != event.inaxes:\n",
    "            with out:\n",
    "                print(\"outside\")\n",
    "            return\n",
    "\n",
    "        pos = (event.ydata, event.xdata)\n",
    "\n",
    "        with out:\n",
    "            print(\"on_click\", pos)\n",
    "            \n",
    "            \n",
    "        res_frame = resize_frame(self.frame)\n",
    "        kp_grid = key_point_grid(self.orb, res_frame)\n",
    "        print(\"len(kp_grid)\", len(kp_grid))\n",
    "\n",
    "\n",
    "        grid_offset_x = ((self.frame.shape[0] - 32) % stride)/2.0 + 16\n",
    "        grid_offset_y = ((self.frame.shape[1] - 32) % stride)/2.0 + 16\n",
    "        g_pos = (int(math.floor((pos[0]-grid_offset_x)/stride)), int(math.floor((pos[1]-grid_offset_y)/stride)))\n",
    "\n",
    "        print(\"g_pos\", g_pos)\n",
    "        path = []\n",
    "\n",
    "        for i in range(playback_random_walk_length):\n",
    "            g_pos, pos = next_pos_play(kp_grid, res_frame.shape, g_pos)\n",
    "            print(\"g_pos, pos\", g_pos, pos)\n",
    "            if g_pos is None:\n",
    "                break\n",
    "            path.append(pos)\n",
    "\n",
    "        path = list(set(path))\n",
    "\n",
    "        windows = np.array([extract_window(res_frame, p) for p in path])\n",
    "\n",
    "        preprocess_input(windows)\n",
    "        features = self.model.predict(windows)\n",
    "        features = features.reshape((windows.shape[0], 512))\n",
    "        \n",
    "        print(\"windows.shape, feats.shape\", windows.shape, features.shape)\n",
    "        show_patches(windows, features, path, frame.shape, self.memory_graph)\n",
    "        \n",
    "            \n",
    "    def update_ax1(self):\n",
    "        self.ax1.cla()\n",
    "        self.ax1.axis(\"off\")\n",
    "        self.ax1.imshow(cv2.cvtColor(self.frame, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "    def update_ax2(self):\n",
    "        self.ax2.cla()\n",
    "        self.ax2.axis(\"off\")\n",
    "        self.ax2.imshow(self.patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "playback_random_walk_length = 10\n",
    "\n",
    "walk_length = 100\n",
    "window_size = 32\n",
    "stride = 16\n",
    "\n",
    "runs = 1\n",
    "max_frames=30*15\n",
    "walker_count = 200\n",
    "\n",
    "video_dir = '../media/Tabletop Objects/videos/'\n",
    "video_files = [f for f in listdir(video_dir) if f.endswith('.mp4') and isfile(join(video_dir, f))][:1]\n",
    "random.shuffle(video_files)\n",
    "\n",
    "db_path = \"../data/tabletop_objects.db\"\n",
    "\n",
    "save_windows = True\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# build_graph()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fe456f958f747fea52a9e68f698cb10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ab8b544a3e9489e823de0bdd1bae142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "video_file = \"../media/Tabletop Objects/videos/001_apple.mp4\"\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12,14), dpi= 100)\n",
    "\n",
    "browser = VideoPatchBrowser(video_file, ax1, ax2)\n",
    "\n",
    "fig.canvas.mpl_connect('button_release_event', browser.on_click)\n",
    "fig.canvas.mpl_connect('key_press_event', browser.on_press)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "ax1.axis(\"off\")\n",
    "ax2.axis(\"off\")\n",
    "\n",
    "out = widgets.Output()\n",
    "display(out)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
